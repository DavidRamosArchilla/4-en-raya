{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install kaggle-environments","metadata":{}},{"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n!curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T22:11:47.723658Z","iopub.execute_input":"2022-06-01T22:11:47.723970Z","iopub.status.idle":"2022-06-01T22:12:04.424294Z","shell.execute_reply.started":"2022-06-01T22:11:47.723914Z","shell.execute_reply":"2022-06-01T22:12:04.423468Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{ \"status\": \"ok\", \"id\": \"21053-1653920676-513498\" }Collecting kaggle-environments>=0.1.6\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/c1/a5cd488a9d0dcd7fcd2730dee47ef26519f063d5fb6a72531ed50b2c73a1/kaggle_environments-1.9.10-py2.py3-none-any.whl (1.9MB)\n\u001b[K     |████████████████████████████████| 1.9MB 599kB/s eta 0:00:01\n\u001b[?25hCollecting Flask>=1.1.2\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/77/59df23681f4fd19b7cbbb5e92484d46ad587554f5d490f33ef907e456132/Flask-2.0.3-py3-none-any.whl (95kB)\n\u001b[K     |████████████████████████████████| 102kB 10.0MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.6/site-packages (from kaggle-environments>=0.1.6) (3.2.0)\nCollecting numpy>=1.19.5\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/32/d3fa649ad7ec0b82737b92fefd3c4dd376b0bb23730715124569f38f3a08/numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8MB)\n\u001b[K     |████████████████████████████████| 14.8MB 36.9MB/s eta 0:00:01\n\u001b[?25hCollecting requests>=2.25.1\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/61/08076519c80041bc0ffa1a8af0cbd3bf3e2b62af10435d269a9d0f40564d/requests-2.27.1-py2.py3-none-any.whl (63kB)\n\u001b[K     |████████████████████████████████| 71kB 7.3MB/s  eta 0:00:01\n\u001b[?25hCollecting Jinja2>=3.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/9a/e5d9ec41927401e41aea8af6d16e78b5e612bca4699d417f646a9610a076/Jinja2-3.0.3-py3-none-any.whl (133kB)\n\u001b[K     |████████████████████████████████| 143kB 44.1MB/s eta 0:00:01\n\u001b[?25hCollecting itsdangerous>=2.0\n  Downloading https://files.pythonhosted.org/packages/9c/96/26f935afba9cd6140216da5add223a0c465b99d0f112b68a4ca426441019/itsdangerous-2.0.1-py3-none-any.whl\nCollecting click>=7.1.2\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/a8/0b2ced25639fb20cc1c9784de90a8c25f9504a7f18cd8b5397bd61696d7d/click-8.0.4-py3-none-any.whl (97kB)\n\u001b[K     |████████████████████████████████| 102kB 9.8MB/s eta 0:00:01\n\u001b[?25hCollecting Werkzeug>=2.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/f3/22afbdb20cc4654b10c98043414a14057cd27fdba9d4ae61cea596000ba2/Werkzeug-2.0.3-py3-none-any.whl (289kB)\n\u001b[K     |████████████████████████████████| 296kB 42.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kaggle-environments>=0.1.6) (0.23)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kaggle-environments>=0.1.6) (0.15.6)\nRequirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kaggle-environments>=0.1.6) (1.13.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kaggle-environments>=0.1.6) (42.0.1.post20191125)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kaggle-environments>=0.1.6) (19.3.0)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /opt/conda/lib/python3.6/site-packages (from requests>=2.25.1->kaggle-environments>=0.1.6) (2.8)\nCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n  Downloading https://files.pythonhosted.org/packages/06/b3/24afc8868eba069a7f03650ac750a778862dc34941a4bebeb58706715726/charset_normalizer-2.0.12-py3-none-any.whl\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.25.1->kaggle-environments>=0.1.6) (2019.9.11)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.25.1->kaggle-environments>=0.1.6) (1.24.2)\nCollecting MarkupSafe>=2.0\n  Downloading https://files.pythonhosted.org/packages/08/dc/a5ed54fcc61f75343663ee702cbf69831dcec9b1a952ae21cf3d1fbc56ba/MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl\nRequirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from Werkzeug>=2.0->Flask>=1.1.2->kaggle-environments>=0.1.6) (0.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kaggle-environments>=0.1.6) (0.6.0)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kaggle-environments>=0.1.6) (7.2.0)\n\u001b[31mERROR: allennlp 0.9.0 requires flaky, which is not installed.\u001b[0m\n\u001b[31mERROR: allennlp 0.9.0 requires responses>=0.7, which is not installed.\u001b[0m\n\u001b[31mERROR: tensorflow-probability 0.8.0 has requirement cloudpickle==1.1.1, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: rasterio 1.1.1 has requirement click<8,>=4.0, but you'll have click 8.0.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.5.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: hyperopt 0.2.2 has requirement networkx==2.2, but you'll have networkx 2.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: fiona 1.8.11 has requirement click<8,>=4.0, but you'll have click 8.0.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: docs 0.2.2 has requirement networkx==2.2, but you'll have networkx 2.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: cligj 0.5.0 has requirement click<8,>=4.0, but you'll have click 8.0.4 which is incompatible.\u001b[0m\n\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\nInstalling collected packages: MarkupSafe, Jinja2, itsdangerous, click, Werkzeug, Flask, numpy, charset-normalizer, requests, kaggle-environments\n  Found existing installation: MarkupSafe 1.1.1\n    Uninstalling MarkupSafe-1.1.1:\n      Successfully uninstalled MarkupSafe-1.1.1\n  Found existing installation: Jinja2 2.10.3\n    Uninstalling Jinja2-2.10.3:\n      Successfully uninstalled Jinja2-2.10.3\n  Found existing installation: itsdangerous 1.1.0\n    Uninstalling itsdangerous-1.1.0:\n      Successfully uninstalled itsdangerous-1.1.0\n  Found existing installation: Click 7.0\n    Uninstalling Click-7.0:\n      Successfully uninstalled Click-7.0\n  Found existing installation: Werkzeug 0.16.0\n    Uninstalling Werkzeug-0.16.0:\n      Successfully uninstalled Werkzeug-0.16.0\n  Found existing installation: Flask 1.1.1\n    Uninstalling Flask-1.1.1:\n      Successfully uninstalled Flask-1.1.1\n  Found existing installation: numpy 1.17.4\n    Uninstalling numpy-1.17.4:\n      Successfully uninstalled numpy-1.17.4\n  Found existing installation: requests 2.22.0\n    Uninstalling requests-2.22.0:\n      Successfully uninstalled requests-2.22.0\nSuccessfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.3 charset-normalizer-2.0.12 click-8.0.4 itsdangerous-2.0.1 kaggle-environments-1.9.10 numpy-1.19.5 requests-2.27.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create ConnectX Environment","metadata":{}},{"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\nimport numpy as np\nimport time\n\nenv = make(\"connectx\", debug=True)\nenv.render()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-01T22:12:04.428580Z","iopub.execute_input":"2022-06-01T22:12:04.428886Z","iopub.status.idle":"2022-06-01T22:12:04.650852Z","shell.execute_reply.started":"2022-06-01T22:12:04.428822Z","shell.execute_reply":"2022-06-01T22:12:04.650110Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Mi Codigo","metadata":{}},{"cell_type":"code","source":"from abc import abstractmethod\n\nclass IGame:\n\n    @abstractmethod\n    def is_game_over(board, inarow):\n        pass\n\n    @abstractmethod\n    def change_turn(player):\n        pass\n\n    @abstractmethod\n    def get_open_cols(board):\n        pass\n\n    @abstractmethod\n    def make_move(board, col, player):\n        pass\n\n    @abstractmethod\n    def get_turn(board):\n        pass\n\n    @abstractmethod\n    def print_board(board):\n        pass","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:12:04.652834Z","iopub.execute_input":"2022-06-01T22:12:04.653310Z","iopub.status.idle":"2022-06-01T22:12:04.660936Z","shell.execute_reply.started":"2022-06-01T22:12:04.653258Z","shell.execute_reply":"2022-06-01T22:12:04.660220Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\nclass Connectx(IGame):\n    def __init__(self, inarow, rows, cols):\n        self.cols = cols\n        self.rows = rows\n        self.inarow = inarow\n        \n\n    def change_turn(self, player): \n        if player == '1':\n            return '2'\n        else:\n            return '1'\n\n\n    def get_open_cols(self, board):\n        # board is serialized\n        return [i for i in range(self.cols) if board[i] == '0']\n\n    def make_move(self, board, col, player):\n\n        entire_col = [board[i*self.cols + col] for i in range(self.rows)]\n        for i, cell in enumerate(reversed(entire_col)):\n            if cell == '0':\n                board = board[:(self.rows-i-1)*self.cols + col] + player + board[(self.rows-i-1)*self.cols+col+1:]\n                break\n        return board\n\n    def get_turn(self, board):\n        # assuming that '1' always starts playing\n        ones = board.count('1')\n        twos = board.count('2')\n        return '1' if ones == twos else '2'\n\n    def is_game_over(self, board, inarow):\n        '''\n        return the winner or '0' if there is no winner yet\n        '''\n        board2d = self.deserialize_board(board)\n        \n        # rows\n        for i in range(self.rows):\n            previous = ''\n            count = 1\n            for j in range(self.cols):\n                current = board[i*self.cols + j]\n                if previous != '0' and previous == current:\n                    count += 1\n                else:\n                    count = 1\n                if count == inarow:\n                    return current\n                previous = current\n        \n        # columns\n        for i in range(self.cols):\n            previous = ''\n            count = 1\n            for j in range(self.rows):\n                current = board[j*self.cols + i]\n                if previous != '0' and previous == current:\n                    count += 1\n                else:\n                    count = 1\n                if count == inarow:\n                    return current\n                previous = current\n        \n        # positive diagonal\n        for row in range(self.rows-(inarow-1)):\n            for col in range(self.cols-(inarow-1)):\n                window = list(board2d[range(row, row+inarow), range(col, col+inarow)])\n                \n                if window.count('1') == inarow:\n                    return '1'\n                elif window.count('2') == inarow:\n                    return '2'\n\n        # negative diagonal\n        for row in range(inarow-1, self.rows):\n            for col in range(self.cols-(inarow-1)):\n                window = list(board2d[range(row, row-inarow, -1), range(col, col+inarow)])\n                if window.count('1') == inarow:\n                    return '1'\n                elif window.count('2') == inarow:\n                    return '2'\n        return '0' if board.count('0') != 0 else 'draw'\n\n    def print_board(self, board):\n        for i in range(self.rows):\n            print('|', end='')\n            for j in range(self.cols):\n                print(board[i*self.cols + j], end='|')\n            print()\n        print(board)\n    \n    def serialize_board(self, board):\n        return ''.join([str(cell) for row in board for cell in row])\n\n    def deserialize_board(self, board: str):\n        arr = np.array(list(board), dtype=np.int8)\n        arr = arr.reshape((self.rows, self.cols))\n        return arr\n    \n    def get_inputs(self, board, turn):\n        x = self.deserialize_board(board)\n        x1 = np.where(x==2, 1, 0)\n        x2 = np.where(x==1, 1, 0)\n        if turn == '2':\n            x3 = np.ones((self.rows, self.cols))\n        else:\n            x3 = np.zeros((self.rows, self.cols))\n        a = np.expand_dims(np.array([x1, x2, x3]), axis=0)\n        return a","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:12:04.662885Z","iopub.execute_input":"2022-06-01T22:12:04.663394Z","iopub.status.idle":"2022-06-01T22:12:04.698431Z","shell.execute_reply.started":"2022-06-01T22:12:04.663183Z","shell.execute_reply":"2022-06-01T22:12:04.697494Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class MCTS:\n\n    def __init__(self, game: IGame = None, model=None):\n        self.explored = set()\n        self.nodes_parameters = {} # fen: (N, V) N--> times visited, V-->value\n        # self.UCT = {} # fen: UPC (upper confidence tree)\n        self.C = 1.4 # aprox sqrt(2)\n        self.game = game\n        self.probabilities = {}\n        self.model = model\n\n    def get_value(self, result: str, player):\n        if result == '1':\n            return 1 if player == '1' else -1\n\n        elif result == '2':\n            return -1 if player == '1' else 1 \n        else:\n            return 0\n\n    def search(self, s):\n        result = self.game.is_game_over(s, self.game.inarow)\n        if result != '0':\n            v = self.get_value(result, self.game.get_turn(s)) \n            if s not in self.nodes_parameters:\n                self.nodes_parameters[s] = np.array((1, v))\n            else:\n                self.nodes_parameters[s][0] += 1\n            return -v, 1\n\n        childs = self.game.get_open_cols(s)\n\n        if s in self.explored:\n        # choose which node is going to be expanded\n            best_uct = float('-inf')\n            best_child = None\n            turn = self.game.get_turn(s)\n            # best_w = 0\n            n_p = self.nodes_parameters[s][0] # parent's n\n            for a in childs:\n                s_child = self.game.make_move(s, a, turn)\n                n, w = self.nodes_parameters[s_child]\n                p = self.probabilities[s_child]    \n                child_uct = self.get_UCT(n, w, n_p, p)\n                if child_uct > best_uct:\n                    best_uct = child_uct\n                    best_child = a\n            s_aux = self.game.make_move(s, best_child, self.game.get_turn(s))\n            sum_v, sum_n = self.search(s_aux)\n            # propagate the results\n            self.nodes_parameters[s_aux][0] += sum_n\n            self.nodes_parameters[s_aux][1] += sum_v\n\n        \n        else:\n            turn = self.game.get_turn(s)\n            if len(self.explored) == 0:\n                probs, v = self.model.predict(self.game.get_inputs(s, turn))\n                self.add_probs(s, probs)\n            self.explored.add(s)\n            sum_v = 0\n            sum_n = 0\n            for a in childs:\n                s_child = self.game.make_move(s, a, turn)\n                if s_child not in self.nodes_parameters:\n                    # v = self.simulate(s_child, turn, turn)\n                    probs, v = self.model.predict(self.game.get_inputs(s_child, turn))\n                    self.add_probs(s_child, probs)\n                    self.nodes_parameters[s_child] = np.array((1, v))\n                    sum_v += v\n                    sum_n += 1\n                \n            self.nodes_parameters[s][0] += sum_n\n            self.nodes_parameters[s][1] += sum_v\n\n        return -sum_v, sum_n\n    \n    def add_probs(self, state, probs):\n        open_cols = self.game.get_open_cols(state)\n        not_open_cols = [i for i in range(self.game.cols) if i not in open_cols]\n        probs = probs.reshape((self.game.cols,))\n        probs[not_open_cols] = 0\n        for a, prob in enumerate(np.ravel(probs)):\n            child_state = self.game.make_move(state, a, self.game.get_turn(state))\n            self.probabilities[child_state] = prob\n\n    \n\n    def simulate(self, s, color_playing, turn):\n        result = self.game.is_game_over(s, self.game.inarow)\n        while result == '0': \n            move = np.random.choice(self.game.get_open_cols(s))\n            s = self.game.make_move(s, move, turn)\n            result = self.game.is_game_over(s, self.game.inarow)\n            turn = self.game.change_turn(turn)\n        return self.get_value(result, color_playing)\n\n\n    def get_UCT(self, n, w, n_p, p):\n        # return w/n + self.C * np.sqrt(n_p) / (1 + n)\n        return w/n + self.C * p * np.sqrt(np.log(n_p) / (n + 1))\n    \n    def get_pi(self, state, tau=1):\n        pi = []\n        turn = self.game.get_turn(state)\n        open_cols =  self.game.get_open_cols(state)\n        for a in range(self.game.cols):\n            if a not in open_cols:\n                pi.append(0)\n            else:\n                s_child = self.game.make_move(state, a, turn)\n                pi.append(self.nodes_parameters[s_child][0])\n        pi = np.power(pi, tau) \n        pi_sum = np.sum(pi)\n        return np.divide(pi, pi_sum)\n    \n    def iterate(self, s, n_iters=None, time_limit=None):\n        self.nodes_parameters[s] = np.array((1, 0))\n        if time_limit is not None:\n            end_time = time.time() + time_limit\n            while time.time() < end_time:\n                v, n = self.search(s)\n                self.nodes_parameters[s][0] += n\n                self.nodes_parameters[s][1] += v\n        else:            \n            for _ in range(n_iters):\n                v, n = self.search(s)\n                self.nodes_parameters[s][0] += n\n                self.nodes_parameters[s][1] += v\n\n    def best_move(self, board, turn, n_iters=None, time_limit=None):\n        self.iterate(board, n_iters=n_iters, time_limit=time_limit)\n        max_n = 0\n        best_move = 3 # por ejemplo 3\n        for a in self.game.get_open_cols(board):\n            c_aux = self.game.make_move(board, a, turn)\n            if self.game.is_game_over(c_aux, self.game.inarow) != '0':\n                return a\n            current_n = self.nodes_parameters[c_aux][0]\n            if current_n > max_n:\n                max_n = current_n\n                best_move = a\n            # print(f'N: {self.nodes_parameters[c_aux][0]} , V: {self.nodes_parameters[c_aux][1]}')\n            # self.game.print_board(c_aux)\n        return best_move\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:12:04.701674Z","iopub.execute_input":"2022-06-01T22:12:04.701994Z","iopub.status.idle":"2022-06-01T22:12:04.744088Z","shell.execute_reply.started":"2022-06-01T22:12:04.701947Z","shell.execute_reply":"2022-06-01T22:12:04.743235Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"\n# Neural Network","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, Dense, BatchNormalization, ReLU, Add, Flatten\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\n\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n   tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\nclass NeuralNetwok():\n    \n\n    def __init__(self, rows, cols, l_rate):\n        self.rows = rows\n        self.cols = cols\n        self.l_rate = l_rate\n        self.N_BLOCKS = 2\n        self.KERNEL_SIZE = (3, 3) # the stride will be 1 (the default used by keras)\n        self.FILTERS = 128\n        self.model = self.create_model(rows, cols, self.N_BLOCKS)\n        \n    \n    def create_model(self, rows, cols, n_blocks):\n        # input of the neural network\n        # 3 channels: one board with the position of th X's,\n        # other with the positions of the O's and the last, all 1 if X plays or all 0 if O plays\n        input_layer = Input(shape=(3, rows, cols))\n        \n        # body (residual blocks)\n        x = self.add_convolutional_layer(input_layer, self.FILTERS, self.KERNEL_SIZE)\n        for _ in range(n_blocks):\n            x = self.add_residual_block(x)\n            \n        # add policy head\n        policy_head_output = self.add_policy_head(x)\n        \n        # add value head\n        value_head_output = self.add_value_head(x)\n        \n        model = Model(inputs=input_layer, outputs=[policy_head_output, value_head_output])\n        model.compile(\n            optimizer = Adam(self.l_rate),\n            loss = ['categorical_crossentropy','mean_squared_error']\n        )\n        return model\n        \n    def add_residual_block(self, x):\n        # first convolutional layer\n        y = self.add_convolutional_layer(x, self.FILTERS, self.KERNEL_SIZE)\n        \n        # second convolutional layer\n        y = Conv2D(self.FILTERS, self.KERNEL_SIZE, data_format='channels_first', padding='same')(y)\n        y = BatchNormalization()(y)\n        y = Add()([x, y])\n        y = ReLU()(y)\n        return y\n    \n    def add_convolutional_layer(self, x, filters, kernel_size):\n        y = Conv2D(filters, kernel_size, data_format='channels_first', padding='same')(x)\n        # padding has to be 'same' in order to keep the dimensions right\n        # data_format=channels_first corresponds to inputs with shape (batch_size, channels, height, width).\n        y = BatchNormalization()(y)\n        y = ReLU()(y)\n        return y\n    \n    def add_policy_head(self, x):\n        y = self.add_convolutional_layer(x, 2, (1, 1))\n        y = Flatten()(y)\n        y = Dense(self.cols, activation='softmax')(y) # TODO: podria llegar a hacerse de tamaño rows*cols, ni idea\n        # move logit probabilities\n        return y\n    \n    def add_value_head(self, x):\n        y = self.add_convolutional_layer(x, 1, (1, 1))\n        y = Flatten()(y)\n        y = Dense(128)(y)\n        y = ReLU()(y)\n        y = Dense(1, activation='tanh')(y)\n        return y\n    \n    def predict(self, x):\n        return self.model.predict(x)\n    \n    def train(self, x, y):\n        history = self.model.fit(epochs=10,\n                                 batch_size=128,\n                                 x=x, \n                                 y=y,\n                                 verbose=1)\n            \n    def save(self, file_name):\n        self.model.save(file_name)\n\n    @staticmethod\n    def load_network(file_name, lr=0.01):\n        model = load_model(file_name)\n        return NeuralNetwok(6, 7, lr)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:12:04.745881Z","iopub.execute_input":"2022-06-01T22:12:04.746370Z","iopub.status.idle":"2022-06-01T22:12:10.446793Z","shell.execute_reply.started":"2022-06-01T22:12:04.746314Z","shell.execute_reply":"2022-06-01T22:12:10.446056Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"nn = NeuralNetwok(6, 7, 0.01)\n# plot_model(nn.model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:12:10.448267Z","iopub.execute_input":"2022-06-01T22:12:10.448577Z","iopub.status.idle":"2022-06-01T22:12:12.644173Z","shell.execute_reply.started":"2022-06-01T22:12:10.448527Z","shell.execute_reply":"2022-06-01T22:12:12.643441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom threading import Thread, Barrier\n\nclass Player:\n    \n    def __init__(self, mcts):\n        self.mcts = mcts\n        \n    def play(self, iterations, num_games):\n        for i in range(iterations):\n            neural_network = self.mcts.model\n            neural_network.save(f'model_iter_{i}.h5')\n            \n            # initialize the arrays\n            # x, pi_s, results = self.generate_examples() # TODO: usar el metodo paralelo\n            examples = self.generate_examples_parallel(f'model_iter_{i}.h5', 4)\n            x, pi_s, results = examples[0]\n            for example in examples[1:]:\n                    x = np.vstack((x, example[0]))\n                    print(example[1].shape)\n                    pi_s = np.vstack((pi_s, example[1]))\n                    results = np.concatenate((results, example[2]))\n            print(pi_s.shape)\n            for j in range(num_games - 1):\n                print(f'generating data for iteration {i} and game {j}')\n                # states, pi, result = self.generate_examples()\n                # x = np.vstack((x, states))\n                # print(pi.shape)\n                # pi_s = np.vstack((pi_s, pi))\n                # results = np.concatenate((results, result))\n                examples = self.generate_examples_parallel(f'model_iter_{i}.h5', 4)\n                for example in examples:\n                    x = np.vstack((x, example[0]))\n                    print(example[1].shape)\n                    pi_s = np.vstack((pi_s, example[1]))\n                    results = np.concatenate((results, example[2]))\n                \n            y = (pi_s, results.reshape(-1, 1))\n            print(x.shape)\n            print(y[0].shape)\n            print(y[1].shape)\n            neural_network.train(x, y)\n           \n            old_network = NeuralNetwok.load_network(f'model_iter_{i}.h5')\n            neural_network.save(f'model_iter_{i}_trained.h5')\n            win_rate = self.simulate_games_parallel(f'model_iter_{i}.h5', f'model_iter_{i}_trained.h5', games_per_thread=10, n_threads=4)\n            # win_rate = self.simulate_games(old_network, 25) # TODO: usar variable global\n            print(f'winrate of the {i}th iteration: {win_rate}')\n            # if the trained network is not much better than the previous one, then the previous one remains as the current network\n            if win_rate < 0.55:\n                self.mcts.model = old_network\n            \n    \n    def generate_examples(self):\n        states = []\n        pi_s = []\n        board = '0' * (self.mcts.game.rows * self.mcts.game.cols)\n        result = '0'\n        current_turn = '1'\n        while result == '0':\n            move = self.mcts.best_move(board, current_turn, n_iters=25)\n            pi = self.mcts.get_pi(board)\n            print(f'pi: {pi}')\n            pi_s.append(pi)\n            board = self.mcts.game.make_move(board, move, current_turn)\n            states.append(self.mcts.game.get_inputs(board, current_turn)[0])\n            result = self.mcts.game.is_game_over(board, self.mcts.game.inarow)\n            current_turn = self.mcts.game.change_turn(current_turn)\n        total_moves = len(states)\n        results = np.ones(total_moves)\n        self.mcts.game.print_board(board)\n        if result == '1':\n            results[1::2] = -1\n        elif result == '2':\n            results[::2] = -1\n        else:\n            results = np.zeros(total_moves)\n            \n        return (states, np.array(pi_s), results)\n\n    def generate_examples_parallel(self, path_current_model, n_threads):\n        barrier = Barrier(n_threads + 1)\n        examples = [0] * n_threads\n        rows = self.mcts.game.rows\n        cols = self.mcts.game.cols\n        inarow = self.mcts.game.inarow\n        model = NeuralNetwok.load_network(path_current_model)\n        def generate(thread_id):\n            game = Connectx(inarow, rows, cols)\n            mcts = MCTS(game, model)\n            states = []\n            pi_s = []\n            board = '0' * (rows * cols)\n            result = '0'\n            current_turn = '1'\n            while result == '0':\n                move = mcts.best_move(board, current_turn, n_iters=25)\n                pi = mcts.get_pi(board)\n                pi_s.append(pi)\n                board = game.make_move(board, move, current_turn)\n                states.append(game.get_inputs(board, current_turn)[0])\n                result = game.is_game_over(board, game.inarow)\n                current_turn = game.change_turn(current_turn)\n            total_moves = len(states)\n            results = np.ones(total_moves)\n            if result == '1':\n                results[1::2] = -1\n            elif result == '2':\n                results[::2] = -1\n            else:\n                results = np.zeros(total_moves)\n            examples[thread_id] = (states, np.array(pi_s), results)\n            print(f'thread {thread_id} ended, result: {result}')\n            barrier.wait()\n\n        for thread_id in range(n_threads):\n            t = Thread(target=generate, args=[thread_id])\n            t.start()\n        barrier.wait()\n        return examples\n    \n    def simulate_games(self, old_network, num_games):\n        old_mcts = MCTS()\n        old_mcts.game = self.mcts.game\n        old_mcts.model = old_network\n        num_wins = 0\n        for i in range(num_games):\n            color_old_network = '1' if np.random.uniform() < 0.5 else '2'\n            color_new_network = '2' if color_old_network == '1' else '1'\n            result = self.play_one_game(old_mcts, color_old_network)\n            if result == color_new_network:\n                num_wins += 1\n        return num_wins / num_games\n        \n    def play_one_game(self, rival, rival_color):\n        board = '0' * (self.mcts.game.rows * self.mcts.game.cols)\n        result = '0'\n        is_rival_turn = rival_color == '1'\n        current_player_color = '2' if is_rival_turn else '1'\n        while result == '0':\n            if is_rival_turn:\n                move = rival.best_move(board, rival_color, n_iters=25) # TODO: usar variables globales para n_iters\n                board = self.mcts.game.make_move(board, move, rival_color)\n            else:\n                move = self.mcts.best_move(board, current_player_color, n_iters=40)\n                board = self.mcts.game.make_move(board, move, current_player_color)\n            is_rival_turn = not is_rival_turn\n            result = self.mcts.game.is_game_over(board, self.mcts.game.inarow)\n        return result\n    # TODO: el fallo esta por aqui\n    def simulate_games_parallel(self, old_network_path, current_network_path, games_per_thread, n_threads):\n        barrier = Barrier(n_threads + 1)\n        rows = self.mcts.game.rows\n        cols = self.mcts.game.cols\n        inarow = self.mcts.game.inarow\n        game = self.mcts.game\n        wins = [0] * n_threads\n        def play_game(thread_id):\n            board = '0' * (rows * cols)\n            result = '0'\n            old_network = NeuralNetwok.load_network(old_network_path)\n            current_network = NeuralNetwok.load_network(current_network_path)\n            for i in range(games_per_thread):\n                old_mcts = MCTS(game, old_network)\n                current_mcts = MCTS(game, current_network)\n                color_old_network = '1' if np.random.uniform() < 0.5 else '2'\n                is_old_net_turn = color_old_network == '1'\n                current_player_color = '2' if is_old_net_turn else '1'\n                while result == '0':\n                    if is_old_net_turn:\n                        move = old_mcts.best_move(board, color_old_network, n_iters=25) # TODO: usar variables globales para n_iters\n                        board = game.make_move(board, move, color_old_network)\n                    else:\n                        move = current_mcts.best_move(board, current_player_color, n_iters=40)\n                        board = game.make_move(board, move, current_player_color)\n                    is_old_net_turn = not is_old_net_turn\n                    result = game.is_game_over(board, inarow)\n\n                if result == current_player_color:\n                    wins[thread_id] += 1\n                game.print_board(board)\n                print(f'result of game {i} in thread {thread_id}: {result}')\n            barrier.wait()\n\n        for thread_id in range(n_threads):\n            t = Thread(target=play_game, args=[thread_id])\n            t.start()\n        barrier.wait()\n        print(wins)\n        return sum(wins) / (games_per_thread * n_threads)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:29:30.683651Z","iopub.execute_input":"2022-06-01T22:29:30.684034Z","iopub.status.idle":"2022-06-01T22:29:30.742801Z","shell.execute_reply.started":"2022-06-01T22:29:30.683970Z","shell.execute_reply":"2022-06-01T22:29:30.742111Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Train the neural network","metadata":{}},{"cell_type":"code","source":"game = Connectx(4, 6, 7)\nnn = NeuralNetwok(6, 7, 0.01)\nmcts = MCTS(game, nn)\nplayer = Player(mcts)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:29:32.060787Z","iopub.execute_input":"2022-06-01T22:29:32.061142Z","iopub.status.idle":"2022-06-01T22:29:32.432657Z","shell.execute_reply.started":"2022-06-01T22:29:32.061091Z","shell.execute_reply":"2022-06-01T22:29:32.431801Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"player.play(100, 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:29:32.725865Z","iopub.execute_input":"2022-06-01T22:29:32.726245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n","metadata":{}},{"cell_type":"code","source":"import functools\n# This agent random chooses a non-empty column.\n\ndef my_agent(observation, configuration):\n    board = functools.reduce(lambda x, y: str(x) + str(y), observation.board)\n    game = Connectx(configuration.inarow, configuration.rows, configuration.columns)\n    mcts = MCTS(game, nn)\n    turn = str(observation.mark)\n    \n#     print(turn, configuration.rows, configuration.columns)\n#     print(board)\n    game.print_board(board)\n    move = mcts.best_move(board, turn, n_iters=40)\n    for a in mcts.game.get_open_cols(board):\n        c_aux = mcts.game.make_move(board, a, turn)\n        print(f'N: {mcts.nodes_parameters[c_aux][0]} , V: {mcts.nodes_parameters[c_aux][1]}')\n#     print(move)\n    return move","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:48:48.273012Z","iopub.execute_input":"2022-05-26T13:48:48.273499Z","iopub.status.idle":"2022-05-26T13:48:48.282956Z","shell.execute_reply.started":"2022-05-26T13:48:48.273443Z","shell.execute_reply":"2022-05-26T13:48:48.281937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test your Agent","metadata":{}},{"cell_type":"code","source":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"negamax\", my_agent])\nenv.render(mode=\"ipython\", width=500, height=450)","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:48:48.284587Z","iopub.execute_input":"2022-05-26T13:48:48.28511Z","iopub.status.idle":"2022-05-26T13:49:28.515452Z","shell.execute_reply.started":"2022-05-26T13:48:48.284913Z","shell.execute_reply":"2022-05-26T13:49:28.514634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Debug/Train your Agent","metadata":{}},{"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","metadata":{"execution":{"iopub.status.busy":"2022-05-26T13:49:28.517332Z","iopub.execute_input":"2022-05-26T13:49:28.517868Z","iopub.status.idle":"2022-05-26T13:50:33.468712Z","shell.execute_reply.started":"2022-05-26T13:49:28.517665Z","shell.execute_reply":"2022-05-26T13:50:33.466873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate your Agent","metadata":{}},{"cell_type":"code","source":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) / float(len(rewards))\n\n# Run multiple episodes to estimate its performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:27:33.205674Z","iopub.execute_input":"2022-04-20T21:27:33.205993Z","iopub.status.idle":"2022-04-20T21:47:17.80321Z","shell.execute_reply.started":"2022-04-20T21:27:33.205941Z","shell.execute_reply":"2022-04-20T21:47:17.801646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Play your Agent\nClick on any column to place a checker there (\"manually select action\").","metadata":{}},{"cell_type":"code","source":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([my_agent, None], width=500, height=450)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T17:06:22.740588Z","iopub.execute_input":"2022-05-03T17:06:22.740926Z","iopub.status.idle":"2022-05-03T17:06:31.408044Z","shell.execute_reply.started":"2022-05-03T17:06:22.740872Z","shell.execute_reply":"2022-05-03T17:06:31.407172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Submission File\n\n","metadata":{}},{"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:55:55.249739Z","iopub.execute_input":"2022-04-19T18:55:55.250318Z","iopub.status.idle":"2022-04-19T18:55:55.25931Z","shell.execute_reply.started":"2022-04-19T18:55:55.250264Z","shell.execute_reply":"2022-04-19T18:55:55.258129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","metadata":{}},{"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","metadata":{"execution":{"iopub.status.busy":"2022-04-19T18:58:39.674545Z","iopub.execute_input":"2022-04-19T18:58:39.674956Z","iopub.status.idle":"2022-04-19T18:58:39.697888Z","shell.execute_reply.started":"2022-04-19T18:58:39.67489Z","shell.execute_reply":"2022-04-19T18:58:39.696281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played.","metadata":{}}]}